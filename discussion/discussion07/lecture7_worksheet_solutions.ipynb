{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Picking the right graphical model\n",
    "\n",
    "For each question, choose the graphical model (one of (a) through (e)) that fits it best. If none of the answers works as-is, then pick one and specify **one** arrow/edge you'd need to add for it to be correct.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a | b | c | d | e\n",
    "- | - | - | - | -\n",
    "![](a.png) | ![](b.png) |  ![](c.png) | ![](d.png) | ![](e.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q1.1\n",
    "\n",
    "For this example, we'll model data coming from a smart watch or other wearable device.\n",
    "\n",
    "* $x$ is the average temperature measurement for the last 30 minutes\n",
    "* $y$ is the average heart rate measurement for the last 30 minutes\n",
    "* $z$ is the number of minutes spent exercising in the last 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:  (e), with an optional edge between $x$ and $y$\n",
    "\n",
    "\n",
    "We're choosing between (d) and (e). Intuitively, it seems like it makes more sense to start with a behavioral model for $p(z)$ that reflects how likely someone is to be exercising, and then to construct physiological models $p(y|z)$ and $p(x|z)$ that reflect how exercise impacts heart rate and temperature. This means that the best choice is (e).\n",
    "\n",
    "If you wanted to make the physiological model more sophisticated, you could add an edge from $x$ to $y$ (or $y$ to $x$, depending on your model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2\n",
    "\n",
    "For this example, we'll model data from social media, supposing that we take a survey at a particular time and compare it to data from the hour before the survey was given.\n",
    "\n",
    "* $x$ is the number of cute animal videos watched in the last hour\n",
    "* $y$ is the number of messages sent between users on the platform in the last hour\n",
    "* $z$ is the average happiness score of users in the survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: (d), with an optional edge between $x$ and $y$\n",
    "\n",
    "The key here is that $x$ and $y$ reflect data from the last hour, and $z$ represents the survey results at the end of the hour. Because of this, it makes sense to model how happy you are as a function of watching animal videos and of messaging your friends: $p(z|x, y)$. Then, in the simplest case you can specify separate prior models $p(x)$ and $p(y)$. \n",
    "\n",
    "You can also add an arrow between $x$ and $y$, and make a more sophisticated model $p(x, y)$ that accounts for the fact that they're related. One way to model this: maybe if you watch animal videos, you have less time to message your friends. Another way to model this: maybe if you're watching videos, you're more likely to send messages to your friends sharing the videos.\n",
    "\n",
    "There isn't necessarily one correct answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3\n",
    "\n",
    "For this example, we'll model crops on farms.\n",
    "\n",
    "* $w$ is the amount of pesticide used\n",
    "* $x$ is the amount of total rainfall for the season\n",
    "* $y$ is the number of bugs found in the field\n",
    "* $z$ is the crop yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: (c) with an extra edge from $x$ to $z$\n",
    "\n",
    "In this case, there isn't really any relationship between $w$ and $x$, so we can safely assume they're independent. We can also assume that the bug count is affected by both pesticide use (more pesticide -> fewer bugs) and by rain (more rain -> damper, moister environment -> more bugs). So far, this makes (c) look like the best candidate. The only problem is that (c) doesn't account for the fact that rain affects crop yield: our model for $z$ should depend on the rain too. So, we have to add an extra edge from $x$ to $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4\n",
    "\n",
    "**Your example here**: Come up with example values for $w$, $x$, $y$, and $z$. Try to use an example from a problem you've seen in one of your other classes or in real life.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Independence and conditional independence\n",
    "\n",
    "\n",
    "Consider graphical model (c) above: ![](c.png) Which of the following statements are true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1\n",
    "\n",
    "(a) $x \\perp \\!\\!\\! \\perp w$\n",
    "\n",
    "(b) $w \\perp \\!\\!\\! \\perp x \\mid y$\n",
    "\n",
    "(c) $w \\perp \\!\\!\\! \\perp y$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "(a) **True**: \n",
    "\n",
    "We can see this algebraically by writing out the joint distribution:\n",
    "\n",
    "$$p(w, x, y, z) = p(w)p(x)p(y|w, x) p(z|y)$$\n",
    "\n",
    "Since we're only interested in the relationship between $w$ and $x$, we need to marginalize over $z$ and $y$. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(w, x) \n",
    "&= \\sum_y \\sum_z \\left[p(w)p(x)p(y|w, x) p(z|y)\\right] \\\\\n",
    "&= p(w)p(x) \\sum_y \\sum_z \\left[p(y|w, x) p(z|y)\\right] \\\\\n",
    "&= p(w)p(x) \\sum_y p(y|w, x) \\underbrace{\\left[\\sum_z p(z|y)\\right]}_{=1} \\\\\n",
    "&= p(w)p(x) \\underbrace{\\sum_y p(y|w, x)}_{=1} \\\\\n",
    "&= p(w)p(x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This is precisely the definition of independence, so we're done.\n",
    "\n",
    "Intuitively, when we marginalize a node in a graphical model, parents of that node usually aren't affected.\n",
    "\n",
    "\n",
    "*Side note: when doing these kinds of computations, it's usually fine to gratuitously swap the order of the sums and/or integrals if everything is finite (probability mass functions must sum to 1). If $y$ and/or $z$ were continuous, we could just as easily replace the sums with integrals and repeat the same computation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) **False**: We can follow a similar computation above. From the definition of conditional probability, $p(w, x|y) = \\frac{p(w, x, y)}{p(y)}$. Since this is a distribution over $w$ and $x$, the denominator is a constant.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(w, x|y) \n",
    "&\\propto p(w, x, y) \\\\\n",
    "&= \\sum_z \\left[p(w)p(x)p(y|w, x) p(z|y)\\right] \\\\\n",
    "&= p(w)p(x)p(y|w, x) \\underbrace{\\sum_z p(z|y)}_{=1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "At this point, we can see that the conditional distribution does *not* factor because of the term $p(y|w, x)$, so we can conclude that conditioned on $y$, $w$ and $x$ are *not* independent.\n",
    "\n",
    "**Intuitively**, here are a few examples to illustrate the idea:\n",
    "\n",
    "* $w$ is whether my light switch is on or off, $x$ is whether I have electricity, and $y$ is whether my light is on.\n",
    "  * If I don't know $y$, then knowing $x$ doesn't tell me anything about $z$. But if I see that $y=$OFF, then knowing $w=$ON tells me that $x=$OFF.\n",
    "* $w$ is a prior mean, $x$ is a prior variance, and $y \\sim N(w, x)$.\n",
    "  * In my prior, my mean and variance are independent: knowing $w=0$ doesn't affect what I think about $x$. But, if I observe $y=900$, then knowing that $w=0$ tells me that $x$ is probably at least 300 (since I'd need a large variance to observe such a large $y$ in a zero-mean normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 (optional)\n",
    "\n",
    "\n",
    "(a) $w \\perp \\!\\!\\! \\perp z \\mid y$\n",
    "\n",
    "(b) $w \\perp \\!\\!\\! \\perp z \\mid z$\n",
    "\n",
    "(c) $w \\perp \\!\\!\\! \\perp z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "(a) **True**: in the graphical model, $z$ depends on $y$, which depends on $w$. \n",
    "\n",
    "(b)(i) This question has a typo: as written, this question is a little weird: we don't usually condition on a random variable taking on a particular value and ask whether it's independent of other things. After all, once we condition on $z$, we can think of it as being fixed.\n",
    "\n",
    "(b)(ii) This question was originally intended to be $w \\perp \\!\\!\\! \\perp x | z$, which is **False**. Intuitively, conditioning on $z$ affects what we know about $y$, which means that we're in a situation similar to 2.1(b). If we were to work through similar algebra involving the distributions, we'd see that marginalizing over $y$ leads effectively to terms that look like $p(z|w, x)$.\n",
    "\n",
    "(c) **False**: without knowing the value of $y$, $w$ and $z$ are not independent: $w$ impacts $z$ through $y$. If we were to work through marginalizing over $x$ and $y$, we'd see that the joint distribution does not factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Review): The multivariate normal distribution\n",
    "\n",
    "This question isn't related to the lecture, but it's meant to review the multivariate normal distribution.\n",
    "\n",
    "Recall that a $d$-dimensional vector $x = (x_1, x_2, \\ldots, x_d)$ has the [*multivariate normal distribution*](http://prob140.org/textbook/content/Chapter_23/02_Multivariate_Normal_Distribution.html) with mean vector $\\mu$ and covariance matrix $\\Sigma$ when\n",
    "\n",
    "$$p(x) \\propto \\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1\n",
    "\n",
    "Show that if $\\Sigma = \\sigma^2 I$ for some scalar $\\sigma$ (where $I$ is the identity matrix), then the individual random variables $x_1, \\ldots, x_d$ are all independent.\n",
    "\n",
    "*Hint: Don't worry about the normalizing constant.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "$$p(x) \\propto \\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T \\left(\\sigma^2I\\right)^{-1} (x-\\mu)\\right\\}$$\n",
    "\n",
    "The quantity in the exponent is what's called a *quadratic form*: specifically, it looks like $z^T A z$, where $z = (x-\\mu)$ and $A=\\frac{1}{\\sigma^2}I$. A little matrix-vector multiplication shows us that\n",
    "\n",
    "$$z^T A z = \\sum_{i, j} A_{ij} z_i z_j$$\n",
    "\n",
    "In this case, our matrix is diagonal, so \n",
    "\n",
    "$$\n",
    "A_{ij} = \\begin{cases}\n",
    "    \\frac{1}{\\sigma^2} & \\text{if }i=j  \\\\\n",
    "    0 & \\text{if }i \\neq j \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This simplifies the sum to $\\displaystyle \\frac{1}{\\sigma^2}\\sum_i (x_i - \\mu_i)^2$. Plugging back in to our equation for $p(x)$, we get\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x) &\\propto \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_i (x_i - \\mu_i)^2\\right\\} \\\\\n",
    " &= \\prod_i \\exp\\left\\{-\\frac{1}{2\\sigma^2}(x_i - \\mu_i)^2\\right\\} \\\\\n",
    " &= \\prod_i p(x_i)\n",
    " \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "\n",
    "Show that if $y = ax+b$, then $y$ also has a multivariate normal distribution. What are the mean and covariance of $y$? \n",
    "\n",
    "*Hint: Your answer shouldn't require too much algebra: if you find yourself doing a lot of it, there may be an easier way.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: We know that we can find the distribution $p(y)$ by plugging in $x=\\frac{y-b}{a}$ and multiplying by $\\frac{1}{|a|}$ (see the [Prob140 textbook](https://prob140.org/textbook/content/Chapter_16/01_Linear_Transformations.html) for more info).\n",
    "\n",
    "$$\n",
    "p(y) = \\exp\\left\\{-\\frac{1}{2}\\left(\\frac{y-b}{a} - \\mu\\right)^T \\Sigma^{-1}\\left(\\frac{y-b}{a} - \\mu\\right)\\right\\}\n",
    "$$\n",
    "\n",
    "To show that this is multivariate normal, we need it to look like the equation above for $p(x)$: we need to do a little algebra to \"move\" the $b$ and $a$ terms into the mean and covariance of $y$. If we factor out $\\frac{1}{a}$ from both vector expressions, each one becomes $\\frac{1}{a}(y-b-a\\mu)$. After this, if we move the two $\\frac{1}{a}$ expressions into the covariance term in the middle, we get\n",
    "\n",
    "$$\n",
    "p(y) = \\exp\\left\\{-\\frac{1}{2}\\left(y - (b - a\\mu)\\right)^T \\left[a^2\\Sigma\\right]^{-1}\\left(y - (b - a\\mu)\\right)\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the form of a multivariate normal distribution with mean $b-a\\mu$ and covariance $a\\Sigma^2$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
